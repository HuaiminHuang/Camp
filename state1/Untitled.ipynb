{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb293bbc-383f-4c1e-b396-a08e29a6c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ab9ae6-c2e5-43ba-a016-5ae317a64d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e9fbdb-7f34-4c24-9ef6-76031fd6fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python版本: 3.10.18 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:08:55) [MSC v.1929 64 bit (AMD64)]\n",
      "PyTorch版本: 2.5.1+cu118\n",
      "CUDA是否可用: True\n",
      "CUDA版本: 11.8\n",
      "当前GPU设备: 0\n",
      "GPU设备名称: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "可用GPU数量: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA是否可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA版本: {torch.version.cuda}\")\n",
    "    print(f\"当前GPU设备: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU设备名称: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"可用GPU数量: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA不可用 - 可能是CPU版本的PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6643641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def scaled_dot_attention(q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    计算点积注意力 attention = softmax(qk.T/ sqrt(d_k))v\n",
    "\n",
    "    args:\n",
    "        q (batch_size, seq_len_q, d_k), \n",
    "        k (batch_size, seq_len_k, d_k), \n",
    "        v (batch_size, seq_len_v, d_v)\n",
    "    return:\n",
    "        scaled_attention, \n",
    "        attentionweight\n",
    "    \"\"\"\n",
    "    d_k = k.size(-1)\n",
    "\n",
    "    scores = q @ k.transpose(-1,-2) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask ==0, float = \"-inf\")\n",
    "        \n",
    "    attention_weight = F.softmax(scores, dim=-1)\n",
    "    scaled_attention = torch.matmul(attention_weight, v)\n",
    "\n",
    "    return scaled_attention, attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d827eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(1,6,4)\n",
    "k = torch.randn(1,4,4)\n",
    "v = torch.randn(1,4,5)\n",
    "\n",
    "scaled_attention, attention_weight = scaled_dot_attention(q,k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16af121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7149, -0.0963, -0.1478, -0.0407,  0.2928],\n",
       "          [ 0.5236, -0.5029,  0.0528, -1.0003, -0.2526],\n",
       "          [ 0.4343, -0.5855,  0.0497, -0.8911, -0.2477],\n",
       "          [ 0.5488, -0.5088, -0.0192, -0.3413,  0.1439],\n",
       "          [ 1.1156, -0.5996,  0.1530, -0.8195,  0.5239],\n",
       "          [ 0.3151, -0.5996, -0.0101, -0.5088, -0.1551]]]),\n",
       " tensor([[[0.0738, 0.1798, 0.3316, 0.4147],\n",
       "          [0.5277, 0.1932, 0.1021, 0.1770],\n",
       "          [0.4690, 0.2728, 0.1006, 0.1576],\n",
       "          [0.1818, 0.3203, 0.2664, 0.2315],\n",
       "          [0.3385, 0.0814, 0.4508, 0.1294],\n",
       "          [0.2845, 0.3918, 0.1331, 0.1906]]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_attention, attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03f64b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(nn.Module):\n",
    "    def __init__(self, d_model, h):\n",
    "        super().__init__()\n",
    "        assert d_model % h ==0, \"d_model must be divided by head number (h)\"\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.h_dim = d_model // h\n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model) \n",
    "        self.w_v = nn.Linear(d_model, d_model) \n",
    "        self.w_o = nn.Linear(d_model, d_model) \n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        q shape is (batch_size, seq_len_q, d_model)\n",
    "        k shape is (batch_size, seq_len_k, d_model)\n",
    "        v shape is (batch_size, seq_len_v, d_model)\n",
    "        and seq_lenk = seq_len_v\n",
    "        \"\"\"\n",
    "        batch_size, seq_len_q, _ = q.size()\n",
    "        seq_len_k = k.size(1)\n",
    "\n",
    "        Q = self.w_q(q).view(batch_size, seq_len_q, self.h, -1).transpose(1,2)\n",
    "        K = self.w_k(k).view(batch_size, seq_len_k, self.h, -1).transpose(1,2)\n",
    "        V = self.w_v(v).view(batch_size, seq_len_k, self.h, -1).transpose(1,2)\n",
    "\n",
    "         # 检查形状\n",
    "        print(f\"Q shape: {Q.shape}\")  # 应该是 (batch_size, h, seq_len_q, d_k)\n",
    "        print(f\"K shape: {K.shape}\")  # 应该是 (batch_size, h, seq_len_k, d_k)\n",
    "\n",
    "        # 计算点积注意力 (b, h, seq_q, h_dim)\n",
    "        scaled_attention, attention_weight = scaled_dot_attention(Q, K, V, mask=mask)\n",
    "\n",
    "        concat_out = scaled_attention.transpose(1,2).contiguous()\n",
    "        concat_scr = concat_out.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        out = self.w_o(concat_scr)\n",
    "\n",
    "        return out, attention_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84443984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MHA(\n",
       "  (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len_q = 64\n",
    "seq_len_kv = 32\n",
    "d_model = 128\n",
    "q = torch.randn(batch_size, seq_len_q, d_model)\n",
    "k = torch.randn(batch_size, seq_len_kv, d_model)\n",
    "v = k\n",
    "model = MHA(128, 4)\n",
    "model\n",
    "# print(\"model:\", model, \"\\nMHA:\", model(q, k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fd3447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([1, 4, 64, 32])\n",
      "K shape: torch.Size([1, 4, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1304, -0.0331, -0.1133,  ..., -0.0386, -0.1027, -0.0802],\n",
       "          [ 0.0993, -0.0205, -0.0985,  ..., -0.0653, -0.1236, -0.0706],\n",
       "          [ 0.1306, -0.0144, -0.0764,  ..., -0.0397, -0.1126, -0.0456],\n",
       "          ...,\n",
       "          [ 0.0430, -0.0142, -0.1107,  ..., -0.0713, -0.0989, -0.0815],\n",
       "          [ 0.1026, -0.0217, -0.0900,  ..., -0.0851, -0.1228, -0.0165],\n",
       "          [ 0.0868,  0.0154, -0.0860,  ..., -0.0370, -0.1157, -0.0687]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[[0.0514, 0.0294, 0.0280,  ..., 0.0470, 0.0182, 0.0261],\n",
       "           [0.0442, 0.0377, 0.0367,  ..., 0.0371, 0.0312, 0.0278],\n",
       "           [0.0231, 0.0285, 0.0609,  ..., 0.0270, 0.0462, 0.0230],\n",
       "           ...,\n",
       "           [0.0252, 0.0344, 0.0221,  ..., 0.0223, 0.0332, 0.0270],\n",
       "           [0.0144, 0.0128, 0.0547,  ..., 0.0211, 0.0145, 0.0484],\n",
       "           [0.0211, 0.0338, 0.0591,  ..., 0.0509, 0.0146, 0.0203]],\n",
       " \n",
       "          [[0.0464, 0.0240, 0.0463,  ..., 0.0408, 0.0315, 0.0150],\n",
       "           [0.0528, 0.0215, 0.0385,  ..., 0.0444, 0.0372, 0.0204],\n",
       "           [0.0414, 0.0271, 0.0349,  ..., 0.0210, 0.0260, 0.0285],\n",
       "           ...,\n",
       "           [0.0146, 0.0280, 0.0187,  ..., 0.0177, 0.0237, 0.0338],\n",
       "           [0.0247, 0.0207, 0.0352,  ..., 0.0275, 0.0214, 0.0268],\n",
       "           [0.0371, 0.0292, 0.0313,  ..., 0.0335, 0.0262, 0.0271]],\n",
       " \n",
       "          [[0.0339, 0.0272, 0.0204,  ..., 0.0209, 0.0565, 0.0297],\n",
       "           [0.0341, 0.0193, 0.0277,  ..., 0.0179, 0.0377, 0.0348],\n",
       "           [0.0222, 0.0355, 0.0192,  ..., 0.0209, 0.0097, 0.0575],\n",
       "           ...,\n",
       "           [0.0258, 0.0292, 0.0240,  ..., 0.0338, 0.0205, 0.0549],\n",
       "           [0.0348, 0.0332, 0.0271,  ..., 0.0279, 0.0410, 0.0201],\n",
       "           [0.0324, 0.0241, 0.0355,  ..., 0.0223, 0.0394, 0.0391]],\n",
       " \n",
       "          [[0.0447, 0.0205, 0.0189,  ..., 0.0201, 0.0309, 0.0390],\n",
       "           [0.0350, 0.0197, 0.0388,  ..., 0.0443, 0.0307, 0.0383],\n",
       "           [0.0609, 0.0160, 0.0163,  ..., 0.0196, 0.0262, 0.0279],\n",
       "           ...,\n",
       "           [0.0226, 0.0481, 0.0268,  ..., 0.0247, 0.0228, 0.0238],\n",
       "           [0.0330, 0.0182, 0.0245,  ..., 0.0248, 0.0192, 0.0268],\n",
       "           [0.0287, 0.0086, 0.0500,  ..., 0.0372, 0.0159, 0.0338]]]],\n",
       "        grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e94a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
